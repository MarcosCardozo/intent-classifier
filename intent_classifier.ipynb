{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removiendo el espacio de las columnas\n",
    "data.columns = data.columns.str.strip()\n",
    "data['consulta'] = data['consulta'].str.strip()\n",
    "data['intencion'] = data['intencion'].str.strip()\n",
    "\n",
    "print(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort data by intencion\n",
    "data = data.sort_values(by=['intencion'], ascending=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt,test_txt,train_label,test_labels = train_test_split(data['consulta'],data['intencion'],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el texto en una lista de palabras\n",
    "words = []\n",
    "for text in data['consulta']:\n",
    "    words += text_to_word_sequence(text)\n",
    "\n",
    "# Contar el número de palabras únicas\n",
    "unique_words = set(words)\n",
    "num_unique_words = len(unique_words)\n",
    "\n",
    "# Imprimir el número de palabras únicas\n",
    "print(\"Número de palabras únicas: \", num_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words = 350 #el numero de palabras unicas es de 211 entonces agregamos un maximo con holgura\n",
    "classes = np.unique(data['intencion'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts(train_txt)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "for c in train_txt:\n",
    "    ls.append(len(c.split()))   #cada consulta se convierte en una lista de palabras y se cuenta el numero de palabras\n",
    "\n",
    "maxLen=int(np.percentile(ls, 98))   #se calcula el percentil 98 de la lista de palabras\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_txt)   #convierte las consultas en secuencias de tokens\n",
    "print(\"train sequence tokenice:\\n\",train_sequences)\n",
    "\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=maxLen, padding='post')     #rellena con ceros las secuencias para que todas tengan la misma longitud dada por el percentil 98\n",
    "print(\"train sequence pad sequence:\\n\",train_sequences)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_txt)\n",
    "print(\"test sequence tokenice:\\n\",test_sequences)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=maxLen, padding='post')\n",
    "print(\"test sequence tokenice:\\n\",test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder() # codifica las clases en numeros\n",
    "integer_encoded = label_encoder.fit_transform(classes) # codifica las clases en numeros\n",
    "\n",
    "print(\"Clases: \", classes)\n",
    "print(\"Clases codificadas: \", integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "print(\"Onehot catgories:\",onehot_encoder.categories_) # codifica las clases en numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_encoded = label_encoder.transform(train_label) # codifica las clases en numeros\n",
    "\n",
    "train_label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_encoded = train_label_encoded.reshape(len(train_label_encoded), 1)\n",
    "\n",
    "train_label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = onehot_encoder.transform(train_label_encoded)    # codifica las clases en numeros\n",
    "\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora lo mismo pero para los datos de testeo\n",
    "\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "test_labels_encoded = test_labels_encoded.reshape(len(test_labels_encoded), 1)\n",
    "\n",
    "print(\"pre-onehot:\\n\",test_labels)\n",
    "\n",
    "test_labels = onehot_encoder.transform(test_labels_encoded)\n",
    "\n",
    "print(\"\\n\\npos-onehot:\\n\",test_labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
